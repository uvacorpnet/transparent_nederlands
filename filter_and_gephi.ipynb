{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Code to filter transparent nederland data and produce a gephi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": null,
    "collapsed": true,
    "executionInfo": null
   },
   "outputs": [],
   "source": [
    "## All imports go here\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#def delete_after_comma(x): # now done in filter-organizations.py\n",
    "#    ind = x.find(\",\")\n",
    "#    if ind > 0:\n",
    "#        return x[:x.find(\",\")]\n",
    "#    else: return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 1. Filter namen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "collapsed": true,
    "executionInfo": null
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "collapsed": true,
    "executionInfo": null
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2. Merge files to have organizations, political parties and people in one nodes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": null,
    "collapsed": false,
    "executionInfo": null
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.local/lib/python3.4/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/javier/.local/lib/python3.4/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/javier/.local/lib/python3.4/site-packages/ipykernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16375, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.local/lib/python3.4/site-packages/ipykernel/__main__.py:49: FutureWarning: sort(....) is deprecated, use sort_index(.....)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/details-organisationsextracted.csv\",index_col=None)\n",
    "df = df.dropna(subset=[\"organisatie\"])\n",
    "\n",
    "#df[\"organisatie\"] = df[\"organisatie\"].apply(lambda x: delete_after_comma(x)) # now done in filter-organizations.py\n",
    "df2 = df.copy()\n",
    "nodes1 = df2[['b1-nummer',\"organisatie\"]]\n",
    "nodes1.columns = ['Type_x',\"Label\"]\n",
    "nodes1[\"Type_x\"] = 'Org'\n",
    "\n",
    "df = pd.read_csv(\"./data/namen.csv\",index_col=None)\n",
    "nodes2 = df[[\"b1-nummer\",\"partij(en)/fractie(s)\"]]\n",
    "nodes2.columns = [\"Type\",\"Label\"]\n",
    "nodes2[\"Type\"] = 'Party'\n",
    "\n",
    "nodes = pd.merge(nodes1,nodes2,on=\"Label\",how=\"outer\")\n",
    "nodes.loc[nodes[\"Type\"] != \"Party\",\"Type\"]  = nodes.loc[nodes[\"Type\"] != \"Party\",\"Type_x\"]\n",
    "del nodes[\"Type_x\"]\n",
    "\n",
    "nodes[\"Id\"] = [i for i in range(nodes.shape[0])]\n",
    "\n",
    "df = pd.read_csv(\"./data/namen.csv\",index_col=None)\n",
    "df[\"Naam\"] = df[[ 'voorletters', 'voorna(a)m(en)','achternaam']].apply(lambda x: \"{} {} {}\".format(*x),axis=1)\n",
    "\n",
    "nodes3 = df[[\"b1-nummer\",\"Naam\",\"functie\"]]\n",
    "nodes3.columns = [\"b1-nummer\",\"Label\",\"Type_x\"]\n",
    "nodes3[\"Type_x\"] = 'Person'\n",
    "\n",
    "nodes = pd.merge(nodes,nodes3,on=\"Label\",how=\"outer\")\n",
    "nodes = nodes.drop_duplicates(subset=[\"Label\"])\n",
    "\n",
    "nodes.loc[nodes[\"Type_x\"] == \"Person\",\"Type\"]  = 'Person'\n",
    "del nodes[\"Type_x\"]\n",
    "nodes[\"Id\"] = [i for i in range(nodes.shape[0])]\n",
    "\n",
    "\n",
    "\n",
    "b1_to_id = nodes.copy()\n",
    "\n",
    "b1_to_id = b1_to_id.dropna(subset=[\"b1-nummer\"])\n",
    "b1_to_id = b1_to_id[[\"b1-nummer\",\"Id\"]]\n",
    "b1_to_id[\"b1-nummer\"] = b1_to_id[\"b1-nummer\"].apply(lambda x: int(x))\n",
    "\n",
    "label_to_id = nodes.loc[nodes[\"Type\"] != \"Person\",:].copy()\n",
    "label_to_id = label_to_id.dropna(subset=[\"Label\"])\n",
    "label_to_id = label_to_id[[\"Label\",\"Id\"]].sort()\n",
    "label_to_id.columns = [\"Target_label\",\"Id\"]\n",
    "\n",
    "del nodes[\"b1-nummer\"]\n",
    "nodes.to_csv(\"./data/nodes_bipartite.csv\",index=None,sep=\"\\t\")\n",
    "print(nodes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 3. Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": null,
    "collapsed": false,
    "executionInfo": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['b1-nummer', 'rubriek', 'organisatie', 'type', 'waarde', 'datum',\n",
      "       'toelichting', 'date_in', 'date_out'],\n",
      "      dtype='object')\n",
      "(15457, 2)\n",
      "(917, 2)\n"
     ]
    }
   ],
   "source": [
    "## merge so we have an id, and find timestamp\n",
    "\n",
    "def separate_datum_org(date):\n",
    "    if isinstance(date,float): return [np.NaN,np.NaN]\n",
    "    \n",
    "    all_slashes = [m.start() for m in re.finditer('/', date)]\n",
    "    if len(all_slashes) == 0: return [np.NaN,np.NaN]\n",
    "    \n",
    "    date = date.replace(\"00\",\"01\")    \n",
    "    middle_slash = all_slashes[int(len(all_slashes)/2)]\n",
    "    \n",
    "    date_in = date[:middle_slash]\n",
    "    date_out = date[middle_slash+1:]\n",
    "    if len(date_in) < 2 or len(date_in) < 2: return [np.NaN,np.NaN]\n",
    "    try: return parse(date_in,fuzzy=True).date(), parse(date_out,fuzzy=True).date()\n",
    "    except: return [np.NaN,np.NaN]\n",
    "\n",
    "def separate_datum_peop(date):\n",
    "    if isinstance(date,float): return np.NaN\n",
    "    return parse(date).date()\n",
    "\n",
    "df = pd.read_csv(\"./data/details-organisationsextracted.csv\",index_col=None)\n",
    "df = df.dropna(subset=[\"organisatie\"])\n",
    "#df[\"organisatie\"] = df[\"organisatie\"].apply(lambda x: delete_after_comma(x))  # now done in filter-organizations.py\n",
    "dates = df[\"datum\"].apply(lambda x: separate_datum_org(x))\n",
    "date_in, date_out = zip(*dates)\n",
    "df[\"date_in\"] = date_in\n",
    "df[\"date_out\"] = date_out\n",
    "print(df.columns)\n",
    "df = df[[\"b1-nummer\",'organisatie','date_in', 'date_out','rubriek']]\n",
    "\n",
    "df.columns = ['b1-nummer', 'Target_label', 'date_in', 'date_out', 'rubriek']\n",
    "\n",
    "df2 = pd.read_csv(\"./data/namen.csv\",index_col=None,dtype=object)\n",
    "df2[\"date_in\"] = df2[\"begin periode\"].apply(lambda x: separate_datum_peop(x))\n",
    "df2[\"date_out\"] = df2[\"einde periode\"].apply(lambda x: separate_datum_peop(x))\n",
    "df2 = df2[[\"b1-nummer\",'partij(en)/fractie(s)','date_in', 'date_out','functie']]\n",
    "df2.columns = [\"b1-nummer\",'Target_label','date_in', 'date_out','rubriek']\n",
    "df2['rubriek'] = \"-9\"\n",
    "\n",
    "df = pd.concat([df,df2])\n",
    "df[\"b1-nummer\"] = df[\"b1-nummer\"].apply(lambda x: int(x))\n",
    "df = df.dropna(subset=[\"Target_label\"])\n",
    "\n",
    "print(label_to_id.shape)\n",
    "print(b1_to_id.shape)\n",
    "\n",
    "edges = pd.merge(df,b1_to_id,on=\"b1-nummer\",how=\"inner\")\n",
    "del edges[\"b1-nummer\"]\n",
    "edges.columns = ['Target_label', 'date_in', 'date_out', 'rubriek', 'Source']\n",
    "edges = pd.merge(edges,label_to_id,on = \"Target_label\",how=\"inner\")\n",
    "\n",
    "edges = edges.loc[edges[\"Target_label\"] != \"\",:]\n",
    "edges = edges.drop_duplicates()\n",
    "del edges[\"Target_label\"]\n",
    "edges.columns = [\"date_in\",\"date_out\",\"rubriek\",\"Source\",\"Target\"]\n",
    "edges = edges.loc[:,[\"Source\",\"Target\",\"date_in\",\"date_out\",\"rubriek\"]]\n",
    "edges.to_csv(\"./data/edges_bipartite.csv\",index=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "collapsed": true,
    "executionInfo": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter all organizations with degree 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'organisatie'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-01942b308bad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"organisatie\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b1-nummer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"organisatie\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/javier/.local/lib/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1967\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1968\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1969\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1971\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/javier/.local/lib/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1974\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1975\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/javier/.local/lib/python3.4/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/javier/.local/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3210\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3211\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3212\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/javier/.local/lib/python3.4/site-packages/pandas/core/index.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[0;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1759\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'organisatie'"
     ]
    }
   ],
   "source": [
    "## merge so we have an id, and find timestamp\n",
    "\n",
    "def separate_datum_org(date):\n",
    "    if isinstance(date,float): return [np.NaN,np.NaN]\n",
    "    \n",
    "    all_slashes = [m.start() for m in re.finditer('/', date)]\n",
    "    if len(all_slashes) == 0: return [np.NaN,np.NaN]\n",
    "    \n",
    "    date = date.replace(\"00\",\"01\")    \n",
    "    middle_slash = all_slashes[int(len(all_slashes)/2)]\n",
    "    \n",
    "    date_in = date[:middle_slash]\n",
    "    date_out = date[middle_slash+1:]\n",
    "    if len(date_in) < 2 or len(date_in) < 2: return [np.NaN,np.NaN]\n",
    "    try: return parse(date_in,fuzzy=True).date(), parse(date_out,fuzzy=True).date()\n",
    "    except: return [np.NaN,np.NaN]\n",
    "\n",
    "def separate_datum_peop(date):\n",
    "    if isinstance(date,float): return np.NaN\n",
    "    return parse(date).date()\n",
    "\n",
    "df = pd.read_csv(\"./data/details-organisationsextracted.csv\",index_col=None)\n",
    "df = df.dropna(subset=[\"organisatie\"])\n",
    "#df[\"organisatie\"] = df[\"organisatie\"].apply(lambda x: delete_after_comma(x))  # now done in filter-organizations.py\n",
    "df2 = df.groupby(\"organisatie\").count()\n",
    "df2 = df2.loc[df2[\"b1-nummer\"]>1,:]\n",
    "df = df.loc[df2[\"organisatie\"].isin(df2.index),:]\n",
    "df\n",
    "              \n",
    "break\n",
    "\n",
    "\n",
    "dates = df[\"datum\"].apply(lambda x: separate_datum_org(x))\n",
    "date_in, date_out = zip(*dates)\n",
    "df[\"date_in\"] = date_in\n",
    "df[\"date_out\"] = date_out\n",
    "print(df.columns)\n",
    "df = df[[\"b1-nummer\",'organisatie','date_in', 'date_out','rubriek']]\n",
    "\n",
    "df.columns = ['b1-nummer', 'Target_label', 'date_in', 'date_out', 'rubriek']\n",
    "\n",
    "df2 = pd.read_csv(\"./data/namen.csv\",index_col=None,dtype=object)\n",
    "df2[\"date_in\"] = df2[\"begin periode\"].apply(lambda x: separate_datum_peop(x))\n",
    "df2[\"date_out\"] = df2[\"einde periode\"].apply(lambda x: separate_datum_peop(x))\n",
    "df2 = df2[[\"b1-nummer\",'partij(en)/fractie(s)','date_in', 'date_out','functie']]\n",
    "df2.columns = [\"b1-nummer\",'Target_label','date_in', 'date_out','rubriek']\n",
    "df2['rubriek'] = \"-9\"\n",
    "\n",
    "df = pd.concat([df,df2])\n",
    "df[\"b1-nummer\"] = df[\"b1-nummer\"].apply(lambda x: int(x))\n",
    "df = df.dropna(subset=[\"Target_label\"])\n",
    "\n",
    "print(label_to_id.shape)\n",
    "print(b1_to_id.shape)\n",
    "\n",
    "edges = pd.merge(df,b1_to_id,on=\"b1-nummer\",how=\"inner\")\n",
    "del edges[\"b1-nummer\"]\n",
    "edges.columns = ['Target_label', 'date_in', 'date_out', 'rubriek', 'Source']\n",
    "edges = pd.merge(edges,label_to_id,on = \"Target_label\",how=\"inner\")\n",
    "\n",
    "edges = edges.loc[edges[\"Target_label\"] != \"\",:]\n",
    "edges = edges.drop_duplicates()\n",
    "del edges[\"Target_label\"]\n",
    "edges.columns = [\"date_in\",\"date_out\",\"rubriek\",\"Source\",\"Target\"]\n",
    "edges = edges.loc[:,[\"Source\",\"Target\",\"date_in\",\"date_out\",\"rubriek\"]]\n",
    "edges.to_csv(\"./data/edges_bipartite_organizations_filtered.csv\",index=None,sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "colabVersion": "0.1",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
